{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "07fa8df3",
   "metadata": {},
   "source": [
    "### Load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b8903e97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='I am doing well, thank you for asking! How are you today?' additional_kwargs={} response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.0-flash', 'safety_ratings': []} id='run--3573072d-cec3-4b25-827e-9974810ae65c-0' usage_metadata={'input_tokens': 6, 'output_tokens': 16, 'total_tokens': 22, 'input_token_details': {'cache_read': 0}}\n"
     ]
    }
   ],
   "source": [
    "import LLM_builder\n",
    "\n",
    "llm = LLM_builder.loadGoogleGenerativeAI()\n",
    "print(llm.invoke(\"Hello, how are you?\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d20c9c5b",
   "metadata": {},
   "source": [
    "### Define Agent State\n",
    "\n",
    "We'll define the state that our agent will maintain throughout its operation. First, define the [State](https://langchain-ai.github.io/langgraph/concepts/low_level/#state) of the graph.  The State schema serves as the input schema for all Nodes and Edges in the graph.\n",
    "\n",
    "itinerary -> a plan of a journey, including the route and the places that you will visit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b9d7d042",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated, List, TypedDict\n",
    "from langchain.schema import HumanMessage, AIMessage\n",
    "\n",
    "class PlannerState(TypedDict):\n",
    "    \"\"\"The state of the planner agent\"\"\"\n",
    "    messages: Annotated[List[HumanMessage | AIMessage], \"The messages in the conversation\"]\n",
    "    itinerary: str\n",
    "    city: str\n",
    "    user_message: str"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70eb66d5",
   "metadata": {},
   "source": [
    "### Set up prompt\n",
    "#### üîç `MessagesPlaceholder` ‚Äî What It Is\n",
    "\n",
    "`MessagesPlaceholder` is a utility class in LangChain that allows you to insert a dynamic list of chat messages (like previous conversation history) into a `ChatPromptTemplate`.\n",
    "\n",
    "#### üß† Purpose\n",
    "\n",
    "In a chat-based agent or app, you often need to provide the full chat history to the LLM so it can respond contextually. However, you don't want to hardcode the entire history in your prompt. Instead, you want to \"inject\" it dynamically when invoking the prompt.\n",
    "\n",
    "#### üîÅ How MessagesPlaceholder Works Under the Hood\n",
    "- It does not have static content.\n",
    "- It acts as a token in the message template, which gets replaced at runtime.\n",
    "- You must provide the actual content during format() or .invoke() call.\n",
    "\n",
    "#### ‚úÖ Correct Usage:\n",
    "```python\n",
    "    prompt = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", \"You are a helpful assistant.\"),\n",
    "        MessagesPlaceholder(\"chat_history\"),\n",
    "        (\"human\", \"{question}\")\n",
    "    ])\n",
    "\n",
    "    chat_history = [\n",
    "        HumanMessage(content=\"What‚Äôs the weather like in Paris?\"),\n",
    "        AIMessage(content=\"It's sunny in Paris.\"),\n",
    "    ]\n",
    "\n",
    "    final_prompt = prompt.format(\n",
    "        chat_history=chat_history,\n",
    "        question=\"What about tomorrow?\"\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "851cef5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts.chat import ChatPromptTemplate, MessagesPlaceholder\n",
    "\n",
    "itinerary_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"\"\"You are a helpful travel assistant. Create a day trip itinerary for {city} based on the user's interests. \n",
    "    Follow these instructions:\n",
    "    1. Use the below chat conversation and the latest input from Human to get the user interests.\n",
    "    2. Always account for travel time and meal times - if its not possible to do everything, then say so.\n",
    "    3. If the user hasn't stated a time of year or season, assume summer season in {city} and state this assumption in your response.\n",
    "    4. If the user hasn't stated a travel budget, assume a reasonable dollar amount and state this assumption in your response.\n",
    "    5. Provide a brief, bulleted itinerary in chronological order with specific hours of day.\"\"\"),\n",
    "    MessagesPlaceholder(\"chat_history\"),\n",
    "    (\"human\", \"{user_message}\"),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1c2a4cd",
   "metadata": {},
   "source": [
    "### Create node function\n",
    "- ```state.get('messages', None)``` -> `if 'messages' in state: value = state['messages'] else: value = None`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b217f3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_itinerary(state: PlannerState) -> PlannerState:\n",
    "\n",
    "    if not state.get('messages', None) : state['messages'] = []\n",
    "\n",
    "    response = llm.invoke(itinerary_prompt.format_messages(city=state['city'], user_mesage=state['user_message'], chat_history=state['messages']))\n",
    "    print(\"\\nFinal Itinerary: \", response.content)\n",
    "\n",
    "    # Keeps all the previous states and update messages and itinerary\n",
    "    return {\n",
    "        **state,\n",
    "        \"messages\": state['messages'] + [HumanMessage(content=state['user_message']), AIMessage(content=response.content)],\n",
    "        \"itinerary\": response.content\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "265bc311",
   "metadata": {},
   "source": [
    "#### üß† What is `MemorySaver` in LangGraph?\n",
    "`MemorySaver` is a checkpointing mechanism that helps store the state of your graph during execution. This means it remembers the state (a dictionary of values) between steps in your LangGraph-based workflow.\n",
    "\n",
    "#### üîç Why Do You Need This?\n",
    "LangGraph is a stateful graph execution engine. It processes inputs (like user requests) step-by-step through nodes (functions), updating and passing state between them.\n",
    "\n",
    "But what happens if:\n",
    "\n",
    "- The workflow gets interrupted?\n",
    "- You want to resume from where it left off?\n",
    "- You want to debug or inspect what happened at each step?\n",
    "- That's where checkpointing comes in.\n",
    "\n",
    "#### üì¶ MemorySaver ‚Äî How It Works\n",
    "MemorySaver is one of the simplest built-in checkpointers. It\n",
    "- Stores the entire state (i.e., PlannerState) in memory (RAM).\n",
    "- Keeps track of all intermediate steps of the graph execution.\n",
    "- Useful for debugging, local development, and experimentation.\n",
    "- It does not persist data to disk or database ‚Äî it‚Äôs purely in-memory, so if you stop the program, everything is lost.\n",
    "\n",
    "#### üß™ Example Behavior\n",
    "Let‚Äôs say your PlannerState looks like:\n",
    "```python\n",
    "{\n",
    "    \"user_message\": \"Plan a trip with boating and swimming\",\n",
    "    \"city\": \"Seattle\"\n",
    "}\n",
    "```\n",
    "As the state flows through the graph:\n",
    "\n",
    "`input_interests` runs and maybe appends to `state[\"messages\"]`.\n",
    "`create_itinerary` runs and adds `state[\"itinerary\"]`.\n",
    "At each step, MemorySaver stores the state like:\n",
    "```python\n",
    "Step 1: {'user_message': ..., 'city': ...}\n",
    "Step 2: {'user_message': ..., 'city': ..., 'messages': [...]}\n",
    "Step 3: {'user_message': ..., 'city': ..., 'messages': [...], 'itinerary': \"...\"}\n",
    "```\n",
    "You can even inspect all checkpoints after execution using:\n",
    "\n",
    "`memory.data`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b43d9f86",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "\n",
    "workflow = StateGraph(PlannerState)\n",
    "\n",
    "#workflow.add_node(\"input_city\", input_city)\n",
    "# workflow.add_node(\"input_interests\", input_interests)\n",
    "workflow.add_node(\"create_itinerary\", create_itinerary)\n",
    "\n",
    "# workflow.set_entry_point(\"input_interests\")\n",
    "\n",
    "#workflow.add_edge(\"input_city\", \"input_interests\")\n",
    "workflow.add_edge(START, \"create_itinerary\")\n",
    "workflow.add_edge(\"create_itinerary\", END)\n",
    "\n",
    "# The checkpointer lets the graph persist its state\n",
    "# this is a complete memory for the entire graph.\n",
    "memory = MemorySaver()\n",
    "app = workflow.compile(checkpointer=memory)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d17f6e95",
   "metadata": {},
   "source": [
    "### Display the graph structure\n",
    "\n",
    "Finally, we [compile our graph](https://langchain-ai.github.io/langgraph/concepts/low_level/#compiling-your-graph) to perform a few basic checks on the graph structure. We can visualize the graph as a [Mermaid diagram](https://github.com/mermaid-js/mermaid)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "21eb1bbf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image, display\n",
    "display(Image(app.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dcc4ae4",
   "metadata": {},
   "source": [
    "### Define the function that runs the graph\n",
    "\n",
    "When we compile the graph, we turn it into a LangChain Runnable, which automatically enables calling `.invoke()`, `.stream()` and `.batch()` with your inputs. In the following example, we run `stream()` to invoke the graph with inputs\n",
    "\n",
    "`.stream(...)` means you're running the LangGraph in streaming mode, where you get intermediate outputs one by one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b5abd564",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_travel_planner(user_request, config_dict: dict):\n",
    "    \"\"\"\n",
    "    Runs the travel planner agent.\n",
    "    \n",
    "    :param user_request: The user's request.\n",
    "    :param config_dict: The configuration dictionary.\n",
    "    \"\"\"\n",
    "    if user_request is None:\n",
    "        raise ValueError(\"user_request cannot be None\")\n",
    "\n",
    "    if config_dict is None:\n",
    "        raise ValueError(\"config_dict cannot be None\")\n",
    "\n",
    "    print(f\"Current User Request: {user_request}\\n\")\n",
    "    init_input = {\"user_message\": user_request,\"city\" : \"Seattle\"}\n",
    "\n",
    "    for output in app.stream(init_input, config=config_dict, stream_mode=\"values\"):\n",
    "        # print(f\"Output: {output}\")\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c32c9498",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current User Request: Can you create a itinerary for a day trip in Seattle with boating and swimming options. Need a complete plan\n",
      "\n",
      "\n",
      "Final Itinerary:  Okay! I can help you create a day trip itinerary for Seattle with boating and swimming options.\n",
      "\n",
      "Since you haven't specified the time of year, I'll assume you're planning this trip for the **summer season** in Seattle to take advantage of the warmer weather. I'll also assume a reasonable budget of **$200 per person** for activities, food, and transportation.\n",
      "\n",
      "Here's a possible itinerary:\n",
      "\n",
      "*   **9:00 AM:** Start your day with breakfast at **Caffe Ladro** in downtown Seattle. Grab a coffee and pastry to fuel up for the day.\n",
      "*   **10:00 AM:** Head to **Lake Union** for a morning of boating. Rent a boat from the **Northwest Outdoor Center** or **Seattle Boat Company**. You can choose from kayaks, paddleboards, or motorboats, depending on your preference and budget. Enjoy the views of the Seattle skyline and Gas Works Park from the water.\n",
      "*   **12:30 PM:** Have lunch at **Ivar's Acres of Clams** on Pier 54. Enjoy classic seafood dishes with waterfront views.\n",
      "*   **2:00 PM:** Take a ferry to **\n"
     ]
    }
   ],
   "source": [
    "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "\n",
    "user_request = \"Can you create a itinerary for a day trip in Seattle with boating and swimming options. Need a complete plan\"\n",
    "run_travel_planner(user_request, config)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
